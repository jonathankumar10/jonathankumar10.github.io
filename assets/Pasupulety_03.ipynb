{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Conversion and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load_train_pos = pd.read_csv('./dataset/train_dataset/train_pos.csv')\n",
    "data_load_train_neg = pd.read_csv('./dataset/train_dataset/train_neg.csv')\n",
    "data_load_test_pos = pd.read_csv('./dataset/test_dataset/test_pos.csv')\n",
    "data_load_test_neg = pd.read_csv('./dataset/test_dataset/test_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_train = [data_load_train_pos,data_load_train_neg]\n",
    "frames_test = [data_load_test_pos,data_load_test_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = pd.concat(frames_train)\n",
    "dataset_2 = pd.concat(frames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = dataset_1.rename(columns = {'Reviews':0,'Class':1})\n",
    "dataset_2 = dataset_2.rename(columns = {'Reviews':0,'Class':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1[1] = dataset_1[1].replace('positive',1)\n",
    "dataset_1[1] = dataset_1[1].replace('negative',0)\n",
    "dataset_2[1] = dataset_2[1].replace('positive',1)\n",
    "dataset_2[1] = dataset_2[1].replace('negative',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1.to_csv('./dataset/final_pre_train_data.csv')\n",
    "dataset_2.to_csv('./dataset/final_pre_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./dataset/final_pre_train_data.csv')\n",
    "df_train = df_train.drop(['Unnamed: 0'], axis= 1)\n",
    "df_test = pd.read_csv('./dataset/final_pre_test_data.csv')\n",
    "df_test = df_test.drop(['Unnamed: 0'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train.iloc[:,0].values\n",
    "y = df_train.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=df_test.iloc[:,0].values\n",
    "Y_test=df_test.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    \n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"'ve\", \" have\", text)\n",
    "    text = re.sub(r\"'ll\", \" will\", text)\n",
    "    text = re.sub(r\"'re\", \" are\", text)\n",
    "\n",
    "    text = re.sub(r\"[0-9]+\", ' ', text)\n",
    "    text = re.sub(r\"-\", ' ', text)\n",
    "    \n",
    "    \n",
    "    text = text.strip().lower()\n",
    "        \n",
    "    text = re.sub(r\"'\", ' ', text)\n",
    "    \n",
    "   \n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((i, \" \") for i in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    \n",
    "\n",
    "    text = ' '.join([w for w in text.split() if len(w)>1])\n",
    "\n",
    "    # Replace multiple space with one space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    text = ''.join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x)):\n",
    "    x[i]=cleanText(x[i])\n",
    "    \n",
    "for i in range(len(X_test)):\n",
    "    X_test[i]=cleanText(X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division of Data into Train, Development and Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X train, Y train, X dev and Y dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, Y_train, Y_dev = train_test_split(x, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X test and Y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.iloc[0:,0]\n",
    "Y_test = df_test.iloc[0:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Vocab as a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"ain\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can\",\"couldn\",\"couldn't\",\"d\",\"did\",\"didn\",\"didn't\",\"do\",\"does\",\"doesn\",\"doesn't\",\"doing\",\"don\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn\",\"hadn't\",\"has\",\"hasn\",\"hasn't\",\"have\",\"haven\",\"haven't\",\"having\",\"he\",\"her\",\"here\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"i\",\"if\",\"in\",\"into\",\"is\",\"isn\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"just\",\"ll\",\"m\",\"ma\",\"me\",\"mightn\",\"mightn't\",\"more\",\"most\",\"mustn\",\"mustn't\",\"my\",\"myself\",\"needn\",\"needn't\",\"no\",\"nor\",\"not\",\"now\",\"o\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"re\",\"s\",\"same\",\"shan\",\"shan't\",\"she\",\"she's\",\"should\",\"should've\",\"shouldn\",\"shouldn't\",\"so\",\"some\",\"such\",\"t\",\"than\",\"that\",\"that'll\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"these\",\"they\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"ve\",\"very\",\"was\",\"wasn\",\"wasn't\",\"we\",\"were\",\"weren\",\"weren't\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\"won\",\"won't\",\"wouldn\",\"wouldn't\",\"y\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"could\",\"he'd\",\"he'll\",\"he's\",\"here's\",\"how's\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"let's\",\"ought\",\"she'd\",\"she'll\",\"that's\",\"there's\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"what's\",\"when's\",\"where's\",\"who's\",\"why's\",\"would\",\"able\",\"abst\",\"accordance\",\"according\",\"accordingly\",\"across\",\"act\",\"actually\",\"added\",\"adj\",\"affected\",\"affecting\",\"affects\",\"afterwards\",\"ah\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"among\",\"amongst\",\"announce\",\"another\",\"anybody\",\"anyhow\",\"anymore\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apparently\",\"approximately\",\"arent\",\"arise\",\"around\",\"aside\",\"ask\",\"asking\",\"auth\",\"available\",\"away\",\"awfully\",\"b\",\"back\",\"became\",\"become\",\"becomes\",\"becoming\",\"beforehand\",\"begin\",\"beginning\",\"beginnings\",\"begins\",\"behind\",\"believe\",\"beside\",\"besides\",\"beyond\",\"biol\",\"brief\",\"briefly\",\"c\",\"ca\",\"came\",\"cannot\",\"can't\",\"cause\",\"causes\",\"certain\",\"certainly\",\"co\",\"com\",\"come\",\"comes\",\"contain\",\"containing\",\"contains\",\"couldnt\",\"date\",\"different\",\"done\",\"downwards\",\"due\",\"e\",\"ed\",\"edu\",\"effect\",\"eg\",\"eight\",\"eighty\",\"either\",\"else\",\"elsewhere\",\"end\",\"ending\",\"enough\",\"especially\",\"et\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"except\",\"f\",\"far\",\"ff\",\"fifth\",\"first\",\"five\",\"fix\",\"followed\",\"following\",\"follows\",\"former\",\"formerly\",\"forth\",\"found\",\"four\",\"furthermore\",\"g\",\"gave\",\"get\",\"gets\",\"getting\",\"give\",\"given\",\"gives\",\"giving\",\"go\",\"goes\",\"gone\",\"got\",\"gotten\",\"h\",\"happens\",\"hardly\",\"hed\",\"hence\",\"hereafter\",\"hereby\",\"herein\",\"heres\",\"hereupon\",\"hes\",\"hi\",\"hid\",\"hither\",\"home\",\"howbeit\",\"however\",\"hundred\",\"id\",\"ie\",\"im\",\"immediate\",\"immediately\",\"importance\",\"important\",\"inc\",\"indeed\",\"index\",\"information\",\"instead\",\"invention\",\"inward\",\"itd\",\"it'll\",\"j\",\"k\",\"keep\",\"keeps\",\"kept\",\"kg\",\"km\",\"know\",\"known\",\"knows\",\"l\",\"largely\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"lets\",\"like\",\"liked\",\"likely\",\"line\",\"little\",\"'ll\",\"look\",\"looking\",\"looks\",\"ltd\",\"made\",\"mainly\",\"make\",\"makes\",\"many\",\"may\",\"maybe\",\"mean\",\"means\",\"meantime\",\"meanwhile\",\"merely\",\"mg\",\"might\",\"million\",\"miss\",\"ml\",\"moreover\",\"mostly\",\"mr\",\"mrs\",\"much\",\"mug\",\"must\",\"n\",\"na\",\"name\",\"namely\",\"nay\",\"nd\",\"near\",\"nearly\",\"necessarily\",\"necessary\",\"need\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"ninety\",\"nobody\",\"non\",\"none\",\"nonetheless\",\"noone\",\"normally\",\"nos\",\"noted\",\"nothing\",\"nowhere\",\"obtain\",\"obtained\",\"obviously\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"omitted\",\"one\",\"ones\",\"onto\",\"ord\",\"others\",\"otherwise\",\"outside\",\"overall\",\"owing\",\"p\",\"page\",\"pages\",\"part\",\"particular\",\"particularly\",\"past\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"poorly\",\"possible\",\"possibly\",\"potentially\",\"pp\",\"predominantly\",\"present\",\"previously\",\"primarily\",\"probably\",\"promptly\",\"proud\",\"provides\",\"put\",\"q\",\"que\",\"quickly\",\"quite\",\"qv\",\"r\",\"ran\",\"rather\",\"rd\",\"readily\",\"really\",\"recent\",\"recently\",\"ref\",\"refs\",\"regarding\",\"regardless\",\"regards\",\"related\",\"relatively\",\"research\",\"respectively\",\"resulted\",\"resulting\",\"results\",\"right\",\"run\",\"said\",\"saw\",\"say\",\"saying\",\"says\",\"sec\",\"section\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sent\",\"seven\",\"several\",\"shall\",\"shed\",\"shes\",\"show\",\"showed\",\"shown\",\"showns\",\"shows\",\"significant\",\"significantly\",\"similar\",\"similarly\",\"since\",\"six\",\"slightly\",\"somebody\",\"somehow\",\"someone\",\"somethan\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specifically\",\"specified\",\"specify\",\"specifying\",\"still\",\"stop\",\"strongly\",\"sub\",\"substantially\",\"successfully\",\"sufficiently\",\"suggest\",\"sup\",\"sure\",\"take\",\"taken\",\"taking\",\"tell\",\"tends\",\"th\",\"thank\",\"thanks\",\"thanx\",\"thats\",\"that've\",\"thence\",\"thereafter\",\"thereby\",\"thered\",\"therefore\",\"therein\",\"there'll\",\"thereof\",\"therere\",\"theres\",\"thereto\",\"thereupon\",\"there've\",\"theyd\",\"theyre\",\"think\",\"thou\",\"though\",\"thoughh\",\"thousand\",\"throug\",\"throughout\",\"thru\",\"thus\",\"til\",\"tip\",\"together\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"ts\",\"twice\",\"two\",\"u\",\"un\",\"unfortunately\",\"unless\",\"unlike\",\"unlikely\",\"unto\",\"upon\",\"ups\",\"us\",\"use\",\"used\",\"useful\",\"usefully\",\"usefulness\",\"uses\",\"using\",\"usually\",\"v\",\"value\",\"various\",\"'ve\",\"via\",\"viz\",\"vol\",\"vols\",\"vs\",\"w\",\"want\",\"wants\",\"wasnt\",\"way\",\"wed\",\"welcome\",\"went\",\"werent\",\"whatever\",\"what'll\",\"whats\",\"whence\",\"whenever\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"wheres\",\"whereupon\",\"wherever\",\"whether\",\"whim\",\"whither\",\"whod\",\"whoever\",\"whole\",\"who'll\",\"whomever\",\"whos\",\"whose\",\"widely\",\"willing\",\"wish\",\"within\",\"without\",\"wont\",\"words\",\"world\",\"wouldnt\",\"www\",\"x\",\"yes\",\"yet\",\"youd\",\"youre\",\"z\",\"zero\",\"a's\",\"ain't\",\"allow\",\"allows\",\"apart\",\"appear\",\"appreciate\",\"appropriate\",\"associated\",\"best\",\"better\",\"c'mon\",\"c's\",\"cant\",\"changes\",\"clearly\",\"concerning\",\"consequently\",\"consider\",\"considering\",\"corresponding\",\"course\",\"currently\",\"definitely\",\"described\",\"despite\",\"entirely\",\"exactly\",\"example\",\"going\",\"greetings\",\"hello\",\"help\",\"hopefully\",\"ignored\",\"inasmuch\",\"indicate\",\"indicated\",\"indicates\",\"inner\",\"insofar\",\"it'd\",\"keep\",\"keeps\",\"novel\",\"presumably\",\"reasonably\",\"second\",\"secondly\",\"sensible\",\"serious\",\"seriously\",\"sure\",\"t's\",\"third\",\"thorough\",\"thoroughly\",\"three\",\"well\",\"wonder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_frequency = dict()\n",
    "for reviews in X_train:\n",
    "    words = reviews.split()\n",
    "    for word in words:\n",
    "        if word not in word_frequency.keys():\n",
    "            word_frequency[word]=1\n",
    "        else:\n",
    "            word_frequency[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251004"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove words with frequency less than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_less_than_5 = list()\n",
    "for i in word_frequency.keys():\n",
    "    if word_frequency[i]<5:\n",
    "        words_less_than_5.append(i)\n",
    "        \n",
    "for i in words_less_than_5:\n",
    "    del word_frequency[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words from the above list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stopwords:\n",
    "    if i in word_frequency.keys():\n",
    "        del word_frequency[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24499"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing new in this hackneyed romance with characters put into unbelievable situations speaking dialogue that borders on the ridiculous this is an example of another movie put into production before serious script problems were solved do not waste your time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train[526])\n",
    "len(X_train[526])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating number of documents containing a particular word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(x,wordfrequency):\n",
    "    wordcount = {}\n",
    "    for word in wordfrequency.keys():\n",
    "        count = 0\n",
    "        for review in x:\n",
    "            if word in review:\n",
    "                count += 1\n",
    "        wordcount[word]= count\n",
    "    return wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wordcount =  word_count(X_train,word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24499"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of the occurance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_occurance(word,dataset):\n",
    "    count = 0\n",
    "    if word not in wordcount.keys():\n",
    "        count\n",
    "    else:\n",
    "        count = wordcount[word]\n",
    "    return count/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P |the| =  0.9959466666666666\n"
     ]
    }
   ],
   "source": [
    "print('P |the| = ',probability_occurance('the',X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional probability based on the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_positive(x,y,wordfrequency):\n",
    "    wordpositive = {}\n",
    "    for word in wordfrequency.keys():\n",
    "        count = 0\n",
    "        for index, reviews in enumerate(x):\n",
    "            if word in reviews and y[index]==1:\n",
    "                count+=1\n",
    "        wordpositive[word] = count\n",
    "    return wordpositive\n",
    "\n",
    "def word_negative(x,y,wordfrequency):\n",
    "    wordnegative = {}\n",
    "    for word in wordfrequency.keys():\n",
    "        count = 0\n",
    "        for index, reviews in enumerate(x):\n",
    "            if word in reviews and y[index]==0:\n",
    "                count+=1\n",
    "        wordnegative[word] = count\n",
    "    return wordnegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wordpositive=word_positive(X_train,Y_train,word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24499"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordpositive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wordnegative=word_negative(X_train,Y_train,word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24499"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordnegative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "occurance of the 'the' in positive document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordpositive['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P[“the” | Positive]  = # of positive documents containing “the” / num of all positive review documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bayes rule:\n",
    "P|positive/the|=(P|the/positive|* P|positive|)/P|the|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sentiment(Y ,sentiment):\n",
    "    length=0\n",
    "    for i in Y:\n",
    "        if i == sentiment:\n",
    "            length+=1\n",
    "    return length\n",
    "\n",
    "def conditional_probability(X,Y,word,sentiment,length):\n",
    "    if sentiment ==1:\n",
    "        count=0\n",
    "        if word not in wordpositive.keys():\n",
    "            count\n",
    "        else:\n",
    "            count = wordpositive[word]\n",
    "    else:\n",
    "        count=0\n",
    "        if word not in wordnegative.keys():\n",
    "            count\n",
    "        else:\n",
    "            count = wordnegative[word]\n",
    "    return count/length\n",
    "\n",
    "def sentiment_probability(Y,sentiment):\n",
    "    count=0\n",
    "    for i in Y:\n",
    "        if i==sentiment:\n",
    "            count+=1\n",
    "    return count/len(Y)\n",
    "\n",
    "def calBayes(X,Y,word,sentiment,length):\n",
    "    a = conditional_probability(X,Y,word,sentiment,length)\n",
    "    b = length/len(Y)\n",
    "    c = probability_occurance(word,X)\n",
    "    if c!= 0:\n",
    "        c = c\n",
    "    else:\n",
    "        c = 0.000001\n",
    "    return ((a*b)/float(c))\n",
    "\n",
    "def calsmoothBayes(X,Y,word,sentiment,length):\n",
    "    count = 0\n",
    "    a = conditional_probability(X,Y,word,sentiment,length)\n",
    "    b = length/len(Y)\n",
    "    c = probability_occurance(word,X)\n",
    "    if word in wordcount.keys():\n",
    "        count = wordcount[word]\n",
    "    else:\n",
    "        count = 2\n",
    "    return  (((a*b)+1)/(c+count)) \n",
    "\n",
    "def review_sentiment(X,Y,review,sentiment,smooth):\n",
    "    summ = 1\n",
    "    length = total_sentiment(Y_train,1)\n",
    "    if smooth == True:\n",
    "        for word in review.split():\n",
    "            prob = calsmoothBayes(X,Y,word,sentiment,length)\n",
    "            summ *= prob\n",
    "    else:\n",
    "        for word in review.split():\n",
    "            prob = calBayes(X,Y,word,sentiment,length)\n",
    "            summ *= prob\n",
    "    return summ\n",
    "\n",
    "def naivesBayes(X,Y,review,smooth):\n",
    "    pos_rev = review_sentiment(X,Y,review,1,smooth)\n",
    "    neg_rev = review_sentiment(X,Y,review,0,smooth)\n",
    "    if pos_rev > neg_rev:\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "def naiveBayesGlobal(X,Y,x_test,smooth):\n",
    "    ypred=[]\n",
    "    for review in x_test:\n",
    "        pred=naivesBayes(X,Y,review,smooth)\n",
    "        ypred.append(pred)\n",
    "    return ypred\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P|the/positive| =  0.995826198630137\n"
     ]
    }
   ],
   "source": [
    "length = total_sentiment(Y_train ,1)\n",
    "print('P|the/positive| = ',conditional_probability(X_train,Y_train,'the',1,length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4982863874906287"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = total_sentiment(Y_train ,1)\n",
    "calBayes(X_train,Y_train,'the',1,length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the sentiment for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: 1\n"
     ]
    }
   ],
   "source": [
    "print('Actual Label: {}'.format(Y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label : 0\n"
     ]
    }
   ],
   "source": [
    "review=X_train[0]\n",
    "pred =naivesBayes(X_train,Y_train,review,smooth=False)\n",
    "print('Predicted Label :',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=naiveBayesGlobal(X_train,Y_train,X_dev,smooth=False)\n",
    "uncleanscore=accuracy_metric(Y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on development set : 82.464 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on development set : {} %'.format(uncleanscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=naiveBayesGlobal(X_train,Y_train,X_dev,smooth=True)\n",
    "uncleanscore=accuracy_metric(Y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on development set : 68.06400000000001 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on development set : {} %'.format(uncleanscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_words(dataset,wordfreq):\n",
    "    for index ,review in enumerate(dataset):\n",
    "        cleanreview=[]\n",
    "        for word in review.split():\n",
    "            if word in wordfreq.keys():\n",
    "                cleanreview.append(word)\n",
    "        cleanreview=' '.join(cleanreview)\n",
    "        dataset[index]=cleanreview\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdev=X_dev.copy()\n",
    "xdev=remove_extra_words(X_dev,word_frequency)\n",
    "y_pred=naiveBayesGlobal(X_train,Y_train,xdev,smooth=False)\n",
    "cleanedscore=accuracy_metric(Y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on cleaned development set : 82.464 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on cleaned development set : {} %'.format(cleanedscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive Top 10 words that predicts positive and negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalpositive = total_sentiment(Y_train ,1)\n",
    "toppositive={}\n",
    "for word in word_frequency.keys():\n",
    "    result=calBayes(X_train,Y_train,word,1,totalpositive)\n",
    "    toppositive[word]=result\n",
    "\n",
    "totalnegative = total_sentiment(Y_train ,0)\n",
    "topnegative={}\n",
    "for word in word_frequency.keys():\n",
    "    result=calBayes(X_train,Y_train,word,0,totalnegative)\n",
    "    topnegative[word]=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10pos = dict(sorted(toppositive.items(), key=operator.itemgetter(1), reverse=True)[:10])\n",
    "top10neg = dict(sorted(topnegative.items(), key=operator.itemgetter(1), reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "krell\n",
      "yokai\n",
      "scola\n",
      "dickey\n",
      "gypo\n",
      "cheadle\n",
      "visconti\n",
      "girotti\n",
      "pappy\n",
      "waxworks\n"
     ]
    }
   ],
   "source": [
    "for word in top10pos.keys():\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frakes\n",
      "sponsors\n",
      "vishal\n",
      "colagrande\n",
      "giada\n",
      "completists\n",
      "dax\n",
      "guernsey\n",
      "greydon\n",
      "drearily\n"
     ]
    }
   ],
   "source": [
    "for word in top10neg.keys():\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the test dataset\n",
    "### Use the optimal hyperparameters you found  and use it to calculate the final accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=remove_extra_words(X_test,word_frequency)\n",
    "y_pred=naiveBayesGlobal(X_train,Y_train,X_test,smooth=True)\n",
    "Finalscore=accuracy_metric(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy : 69.092 %\n"
     ]
    }
   ],
   "source": [
    "print('Final Accuracy : {} %'.format(Finalscore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
